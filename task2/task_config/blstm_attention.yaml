# task
task_key: us2
seq_len: 50

# train
epochs: 5
dropout_keep_prob: 1.
learning_rate_initial: 0.01
learning_rate_decay_rate: 1.
learning_rate_decay_steps: 10
l2_reg_lambda: 0.2

# validation
validate_interval: 1
batch_size: 64

# parameters got when data is loaded
dim_embed:
dim_lexicon_feat:
dim_output:

# embedding
n_vocab: 4000
embedding_algorithm: glove
embedding_key: twitter.50d
# embedding_algorithm: word2vec
# embedding_key: frederic_godin

# model specific parameters
algorithm: blstm_attention
dim_rnn: 50
n_rnn_layers: 2
dim_attention: 25